{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[Colaboratory]TFLite_ModelMaker_Hands_On",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKMNEdXeW5yc"
      },
      "source": [
        "# [Colaboratory]TFLite-ModelMaker-ObjectDetection-Hands-On.ipynb\n",
        "このノートブックはTensorflow Lite Model Makerを用いて物体検出モデルを作成するハンズオン用スクリプトです(This notebook is a hands-on script for creates a custom object detection model using Tensorflow Lite Model Maker)<br><br>\n",
        "Colaboratoryのハードウェア アクセラレータ設定をGPUにして実行してください(Set the hardware accelerator setting of Colaboratory to GPU and execute it.)<br><br>\n",
        "Github URL :https://github.com/Kazuhito00/TFLite-ModelMaker-EfficientDet-Colab-Hands-On"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpv9GEW6YrLb"
      },
      "source": [
        "# パッケージインストール(Install the required packages)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKDt1DYxW5aP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec8233f-4e0c-41ae-c9ca-d0a5e194c4ae"
      },
      "source": [
        "!pip install -q tflite-model-maker"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 593kB 8.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 16.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 15.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 849kB 16.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 28.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 9.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 686kB 28.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.3MB 42.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 50.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 50.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 48.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 46.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 13.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 38.2MB 1.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 54.8MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzAj17_tZIkf"
      },
      "source": [
        "# パッケージインポート(Import the required packages)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5Fa3PoqW5X7"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0sv_ZJxZdLM"
      },
      "source": [
        "# データセット準備(Prepare the dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgcGqpy4Z3fL"
      },
      "source": [
        "!mkdir dataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZSZGDWh3knN"
      },
      "source": [
        "画像ファイルとcsvファイルを「dataset」ディレクトリに格納してください(Store the image file and csv file in the \"dataset\" directory)<br><br>\n",
        "アノテーションのハンズオンを実施しない方や、アノテーション済みのデータを用いて試したい方は、以下の「if False:」を「if True:」に変更して実施してください(If you do not want to perform the annotation hands-on, or if you want to try using the annotated data, change the following \"if False:\" to \"if True:\" and execute it.)\n",
        "![image](https://user-images.githubusercontent.com/37477845/121359484-7fa46d80-c96e-11eb-9491-c262935c4125.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL8Ic_v-ZC9p"
      },
      "source": [
        "if False:\n",
        "    !git clone https://github.com/Kazuhito00/TFLite-ModelMaker-EfficientDet-Colab-Hands-On\n",
        "    !cp -r TFLite-ModelMaker-EfficientDet-Colab-Hands-On/02_dataset\\(Annotated\\)/* ./dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81zl9TcUdDRy"
      },
      "source": [
        "#### データセットCSV読み込み(Read CSV)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoIUHTz3cYMv"
      },
      "source": [
        "dataset_dir = 'dataset'\n",
        "original_csv_name = 'TFLite-ModelMaker-EfficientDet-Colab-Hands-On-export.csv'\n",
        "\n",
        "original_csv_path = os.path.join(dataset_dir, original_csv_name)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "gZkLjTE4cfoT",
        "outputId": "971b8353-f281-4db1-ab15-613377f41d17"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv(original_csv_path)\n",
        "dataset.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>315.351545</td>\n",
              "      <td>73.603745</td>\n",
              "      <td>379.251566</td>\n",
              "      <td>fish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>416.637763</td>\n",
              "      <td>419.751566</td>\n",
              "      <td>517.477126</td>\n",
              "      <td>530.451593</td>\n",
              "      <td>fish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>316.698704</td>\n",
              "      <td>153.351545</td>\n",
              "      <td>434.644797</td>\n",
              "      <td>201.051573</td>\n",
              "      <td>fish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>803.788994</td>\n",
              "      <td>178.551573</td>\n",
              "      <td>861.411516</td>\n",
              "      <td>255.951559</td>\n",
              "      <td>fish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>329.751566</td>\n",
              "      <td>54.696373</td>\n",
              "      <td>380.151552</td>\n",
              "      <td>fish</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        image        xmin        ymin        xmax        ymax label\n",
              "0  000002.jpg    0.000000  315.351545   73.603745  379.251566  fish\n",
              "1  000002.jpg  416.637763  419.751566  517.477126  530.451593  fish\n",
              "2  000002.jpg  316.698704  153.351545  434.644797  201.051573  fish\n",
              "3  000002.jpg  803.788994  178.551573  861.411516  255.951559  fish\n",
              "4  000003.jpg    0.000000  329.751566   54.696373  380.151552  fish"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOnYY5STihaV"
      },
      "source": [
        "#### 学習データ/検証データ/テストデータ 分割(Split Training data/validation data/Test data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO9V2lfPisHD",
        "outputId": "21339c0d-e3e8-4a04-9021-c1900f865d66"
      },
      "source": [
        "# ユニークな名前の画像ファイル数を取得(Get the number of image files with unique names)\n",
        "image_list = sorted(dataset[\"image\"].unique())\n",
        "dataset_num = len(dataset[\"image\"].unique())\n",
        "print('Number of dataset: ' + str(dataset_num))\n",
        "\n",
        "# 学習データ：60%、検証データ 10%、テストデータ 10%(Training data:60%, validation data:20%, Test data:20%)\n",
        "train_num = int(0.6 * dataset_num)\n",
        "validation_num = int(0.2 * dataset_num)\n",
        "test_num = int(0.2 * dataset_num)\n",
        "print('Number of Train dataset: ' + str(train_num))\n",
        "print('Number of Validation dataset: ' + str(validation_num))\n",
        "print('Number of Test dataset: ' + str(test_num))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of dataset: 50\n",
            "Number of Train dataset: 30\n",
            "Number of Validation dataset: 10\n",
            "Number of Test dataset: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl1O7HNWj6o6"
      },
      "source": [
        "# 学習データ/検証データ/テストデータ 分割(Split Training data/validation data/Test data)\n",
        "import random\n",
        "\n",
        "use_shuffle = False\n",
        "\n",
        "if use_shuffle is False:\n",
        "    train_list = image_list[:train_num]\n",
        "    validation_list = image_list[train_num:train_num + validation_num]\n",
        "    test_list = image_list[train_num + validation_num:]\n",
        "else:\n",
        "    image_shuffle_list = random.sample(image_list, len(image_list))\n",
        "    train_list = image_shuffle_list[:train_num]\n",
        "    validation_list = image_shuffle_list[train_num:train_num + validation_num]\n",
        "    test_list = image_shuffle_list[train_num + validation_num:]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfRdYM_30OJ9"
      },
      "source": [
        "# object_detectorで読み込む形式に変換(Convert to format read by object_detector)\n",
        "object_detectorでCSV形式のデータセットを読み込む場合には以下の形式でデータを用意します(When handling CSV format data set with object_detector, prepare the data in the following format)\n",
        "```\n",
        "TRAIN,dataset/000030.jpg,fish,0.711606,0.825651,,,0.932004,0.963984,,\n",
        "VALIDATE,dataset/000031.jpg,fish,0.373974,0.082317,,,0.486518,0.253984,,\n",
        "TEST,dataset/000041.jpg,fish,0.403985,0.183984,,,0.562485,0.320651,,\n",
        "```\n",
        "\n",
        "列1(Column1)：TRAIN、VALIDATE、TEST<br>\n",
        "列2(Column2)：画像格納パス(Image path)<br>\n",
        "列3(Column3)：クラス ラベル名(Class label name)<br>\n",
        "列4(Column4)：左上x座標(Upper left x coordinate)<br>\n",
        "列5(Column5)：左上y座標(Upper left y coordinate)<br>\n",
        "列6(Column6)：右上x座標(Upper right x coordinate) ※指定不要(No need to specify)<br>\n",
        "列7(Column7)：右上y座標(Upper right y coordinate) ※指定不要(No need to specify)<br>\n",
        "列8(Column8)：右下x座標(Lower right x coordinate)<br>\n",
        "列9(Column9)：右下y座標(Lower right y coordinate)<br>\n",
        "列10(Column10)：左下x座標(Lower left x coordinate) ※指定不要(No need to specify)<br>\n",
        "列11(Column11)：左下x座標(Lower left x coordinate) ※指定不要(No need to specify)<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbKPCva8mS3D"
      },
      "source": [
        "import cv2\n",
        "\n",
        "dataset_list = []\n",
        "\n",
        "def convert_csv_format(tag, dataset_list, file_list, dataset_dir):\n",
        "    result_list = []\n",
        "\n",
        "    for target_file in file_list:\n",
        "        for index, row in (dataset_list[dataset_list['image'] == target_file]).iterrows():\n",
        "            file_path = os.path.join(dataset_dir, row.image)\n",
        "            temp_image = cv2.imread(file_path)\n",
        "\n",
        "            image_width, image_height = temp_image.shape[1], temp_image.shape[0]\n",
        "            xmin = row.xmin / image_width\n",
        "            ymin = row.ymin / image_height\n",
        "            xmax = row.xmax / image_width\n",
        "            ymax = row.ymax / image_height\n",
        "\n",
        "            result_list.append([tag, file_path, row.label, xmin, ymin, '', '', xmax, ymax, '', ''])\n",
        "\n",
        "    return result_list\n",
        "\n",
        "result_list = convert_csv_format('TRAIN', dataset, train_list, dataset_dir)\n",
        "dataset_list.extend(result_list)\n",
        "\n",
        "result_list = convert_csv_format('VALIDATE', dataset, validation_list, dataset_dir)\n",
        "dataset_list.extend(result_list)\n",
        "\n",
        "result_list = convert_csv_format('TEST', dataset, test_list, dataset_dir)\n",
        "dataset_list.extend(result_list)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-9cldynZC1U"
      },
      "source": [
        "# CSVファイルに保存(Save CSV)\n",
        "import csv\n",
        "\n",
        "dataset_csv_file = 'dataset.csv'\n",
        "\n",
        "with open(dataset_csv_file, 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(dataset_list)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXAIWxkOpBvc"
      },
      "source": [
        "# Model MakerでCSVファイルを読み込む(Import csv file with Model Maker)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3b6BXw7W5VE"
      },
      "source": [
        "train_data, validation_data, test_data = object_detector.DataLoader.from_csv(dataset_csv_file)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiLjkQDSqKZE"
      },
      "source": [
        "# 物体検出のモデルアーキテクチャを選択(Choose an object detection model archiecture)\n",
        "このハンズオンではEfficientDet-Lite0を使用します(This Hands on uses the EfficientDet-Lite0 model)<br>\n",
        "EfficientDet-Lite は、EfficientDetから派生したモバイル/IoT向けのオブジェクト検出モデルのファミリーです<br>(EfficientDet-Lite are a family of mobile/IoT-friendly object detection models derived from the EfficientDet architecture)<br><br>\n",
        "各 EfficientDet-Lite モデルのパフォーマンスは以下です(The performance of each EfficientDet-Lite model is as follows:)\n",
        "\n",
        "| Model architecture | Size(MB)* | Latency(ms)** | Average Precision*** |\n",
        "|--------------------|-----------|---------------|----------------------|\n",
        "| EfficientDet-Lite0 | 4.4       | 37            | 25.69%               |\n",
        "| EfficientDet-Lite1 | 5.8       | 49            | 30.55%               |\n",
        "| EfficientDet-Lite2 | 7.2       | 69            | 33.97%               |\n",
        "| EfficientDet-Lite3 | 11.4      | 116           | 37.70%               |\n",
        "| EfficientDet-Lite4 | 19.9      | 260           | 41.96%               |\n",
        "\n",
        "<i> * 整数量子化モデルのサイズ(Size of the integer quantized models) <br/>\n",
        "** Pixel 4 で測定したレイテンシ ※CPU 4スレッド(Latency measured on Pixel 4 using 4 threads on CPU) <br/>\n",
        "*** OCO 2017 検証データセットのmAP(Average Precision is the mAP (mean Average Precision) on the COCO 2017 validation dataset)\n",
        "</i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iX7AOBnp4aq"
      },
      "source": [
        "spec = model_spec.get('efficientdet_lite0')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-BSXY5Rr1pb"
      },
      "source": [
        "# 訓練(Training)\n",
        "object_detector.create()を用いてモデルを訓練します(Train the model using object_detector.create())<br>\n",
        "train_whole_modelにTrueを指定した場合、モデルのヘッド部分のみではなくモデル全体を訓練します<br>(If true is specified for train_whole_model, the entire model is trained, not just the head part of the model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pQauA7bp4YU",
        "outputId": "13c0ee54-ff88-4ad8-bf02-3fd96db97539"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = object_detector.create(\n",
        "    train_data, \n",
        "    model_spec=spec,\n",
        "    validation_data=validation_data,\n",
        "    epochs=100,\n",
        "    batch_size=8, \n",
        "    train_whole_model=True, \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 44s 2s/step - det_loss: 1.8252 - cls_loss: 1.1248 - box_loss: 0.0140 - reg_l2_loss: 0.0630 - loss: 1.8882 - learning_rate: 0.0088 - gradient_norm: 1.2512 - val_det_loss: 1.7528 - val_cls_loss: 1.1066 - val_box_loss: 0.0129 - val_reg_l2_loss: 0.0630 - val_loss: 1.8158\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 1s 601ms/step - det_loss: 1.8174 - cls_loss: 1.1139 - box_loss: 0.0141 - reg_l2_loss: 0.0630 - loss: 1.8804 - learning_rate: 0.0100 - gradient_norm: 1.3246 - val_det_loss: 1.7091 - val_cls_loss: 1.0885 - val_box_loss: 0.0124 - val_reg_l2_loss: 0.0630 - val_loss: 1.7721\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 1s 607ms/step - det_loss: 1.7215 - cls_loss: 1.0945 - box_loss: 0.0125 - reg_l2_loss: 0.0630 - loss: 1.7845 - learning_rate: 0.0100 - gradient_norm: 1.3449 - val_det_loss: 1.6529 - val_cls_loss: 1.0572 - val_box_loss: 0.0119 - val_reg_l2_loss: 0.0630 - val_loss: 1.7159\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 1s 614ms/step - det_loss: 1.7353 - cls_loss: 1.0619 - box_loss: 0.0135 - reg_l2_loss: 0.0630 - loss: 1.7983 - learning_rate: 0.0100 - gradient_norm: 1.2131 - val_det_loss: 1.5799 - val_cls_loss: 1.0066 - val_box_loss: 0.0115 - val_reg_l2_loss: 0.0630 - val_loss: 1.6429\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 1s 631ms/step - det_loss: 1.6238 - cls_loss: 0.9944 - box_loss: 0.0126 - reg_l2_loss: 0.0630 - loss: 1.6868 - learning_rate: 0.0100 - gradient_norm: 1.5625 - val_det_loss: 1.4633 - val_cls_loss: 0.9104 - val_box_loss: 0.0111 - val_reg_l2_loss: 0.0630 - val_loss: 1.5263\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 1s 619ms/step - det_loss: 1.4719 - cls_loss: 0.8985 - box_loss: 0.0115 - reg_l2_loss: 0.0630 - loss: 1.5349 - learning_rate: 0.0099 - gradient_norm: 1.6064 - val_det_loss: 1.3014 - val_cls_loss: 0.7650 - val_box_loss: 0.0107 - val_reg_l2_loss: 0.0630 - val_loss: 1.3644\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 1s 629ms/step - det_loss: 1.3402 - cls_loss: 0.7561 - box_loss: 0.0117 - reg_l2_loss: 0.0630 - loss: 1.4032 - learning_rate: 0.0099 - gradient_norm: 1.8559 - val_det_loss: 1.5647 - val_cls_loss: 1.0411 - val_box_loss: 0.0105 - val_reg_l2_loss: 0.0630 - val_loss: 1.6277\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 1s 638ms/step - det_loss: 1.3818 - cls_loss: 0.7293 - box_loss: 0.0130 - reg_l2_loss: 0.0630 - loss: 1.4448 - learning_rate: 0.0099 - gradient_norm: 3.5667 - val_det_loss: 1.8705 - val_cls_loss: 1.3522 - val_box_loss: 0.0104 - val_reg_l2_loss: 0.0630 - val_loss: 1.9335\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 1s 615ms/step - det_loss: 1.2713 - cls_loss: 0.6406 - box_loss: 0.0126 - reg_l2_loss: 0.0630 - loss: 1.3343 - learning_rate: 0.0098 - gradient_norm: 2.3951 - val_det_loss: 1.4685 - val_cls_loss: 0.9444 - val_box_loss: 0.0105 - val_reg_l2_loss: 0.0630 - val_loss: 1.5315\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 1s 647ms/step - det_loss: 1.1231 - cls_loss: 0.5382 - box_loss: 0.0117 - reg_l2_loss: 0.0630 - loss: 1.1861 - learning_rate: 0.0098 - gradient_norm: 1.8549 - val_det_loss: 1.5483 - val_cls_loss: 1.0278 - val_box_loss: 0.0104 - val_reg_l2_loss: 0.0630 - val_loss: 1.6113\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 1s 629ms/step - det_loss: 1.0265 - cls_loss: 0.5184 - box_loss: 0.0102 - reg_l2_loss: 0.0630 - loss: 1.0895 - learning_rate: 0.0097 - gradient_norm: 2.3423 - val_det_loss: 1.4286 - val_cls_loss: 0.9340 - val_box_loss: 0.0099 - val_reg_l2_loss: 0.0630 - val_loss: 1.4916\n",
            "Epoch 12/100\n",
            "2/3 [===================>..........] - ETA: 0s - det_loss: 0.9540 - cls_loss: 0.4708 - box_loss: 0.0097 - reg_l2_loss: 0.0630 - loss: 1.0170 - learning_rate: 0.0097 - gradient_norm: 1.5790"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtDyB-vUx85n"
      },
      "source": [
        "# モデル評価(Model evaluate)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g88cDDKPp4U7"
      },
      "source": [
        "model.evaluate(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Luqqjw9xEHT"
      },
      "source": [
        "# TensorFlow Lite形式でのモデルエクスポート(Export to TensorFlow Lite format)\n",
        "形式：完全整数量子化(Full integer quantization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-DOLjjkxpcT"
      },
      "source": [
        "デフォルトでのエクスポート形式は完全整数量子化です(The default quantization technique is full integer quantization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2fjX1mqp4R4"
      },
      "source": [
        "model.export(export_dir='.', tflite_filename='model_int8.tflite')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXUJrWSWxP93"
      },
      "source": [
        "model.evaluate_tflite('model_int8.tflite', test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hle8aI_1x0dn"
      },
      "source": [
        "# TensorFlow Lite形式でのモデルエクスポート(Export to TensorFlow Lite format)\n",
        "形式：Float16量子化(Float16 quantization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mca6Az-7W5R7"
      },
      "source": [
        "config = QuantizationConfig.for_float16()\n",
        "model.export(export_dir='.', tflite_filename='model_fp16.tflite', quantization_config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLYCwrqHxSNR"
      },
      "source": [
        "model.evaluate_tflite('model_fp16.tflite', test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AThLwnKllCSr"
      },
      "source": [
        "# 推論(Inference)\n",
        "形式：完全整数量子化(Full integer quantization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JsYKdT6-q8a"
      },
      "source": [
        "# モデルロード(Load model)\n",
        "interpreter = tf.lite.Interpreter(model_path='model_int8.tflite')\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecRSKCti-vaX"
      },
      "source": [
        "# 入力情報確認(Check input detail)\n",
        "input_details = interpreter.get_input_details()\n",
        "print(input_details)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2WZ2Bbt-vyk"
      },
      "source": [
        "# 出力情報確認(Check output detail)\n",
        "output_details = interpreter.get_output_details()\n",
        "print(output_details)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV1s4iJi_LPk"
      },
      "source": [
        "# クラスラベル確認(Check class label)\n",
        "class_labels = ['???'] * model.model_spec.config.num_classes\n",
        "label_map = model.model_spec.config.label_map\n",
        "for label_id, label_name in label_map.as_dict().items():\n",
        "    class_labels[label_id-1] = label_name\n",
        "\n",
        "print(class_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PizkkVwf-ycz"
      },
      "source": [
        "# 推論用関数(Function for inference)\n",
        "def run_inference_int8_single_image(\n",
        "        interpreter,\n",
        "        input_image,\n",
        "        input_shape=(320, 320),\n",
        "):\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    x = input_image[:, :, [2, 1, 0]]  # BGR2RGB\n",
        "    x = cv2.resize(x, (input_shape[0], input_shape[1]))\n",
        "    x = x.reshape(1, x.shape[0], x.shape[1], x.shape[2])\n",
        "    x = x.astype(np.uint8)\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], x)\n",
        "    interpreter.invoke()\n",
        "\n",
        "    boxes = interpreter.get_tensor(output_details[0]['index'])\n",
        "    classes = interpreter.get_tensor(output_details[1]['index'])\n",
        "    scores = interpreter.get_tensor(output_details[2]['index'])\n",
        "    num = interpreter.get_tensor(output_details[3]['index'])\n",
        "\n",
        "    return np.squeeze(boxes), np.squeeze(classes), np.squeeze(scores), int(num[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfoiDAk__Cl2"
      },
      "source": [
        "# サンプル画像読み込み(Load sample image)\n",
        "test_image = cv2.imread('dataset/000041.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehH5yysQ_FIE"
      },
      "source": [
        "# 推論(Inference)\n",
        "bboxes, classes, scores, num = run_inference_int8_single_image(\n",
        "    interpreter,\n",
        "    test_image\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH2TH3GI_NuB"
      },
      "source": [
        "# 推論結果描画(Inference result drawing)\n",
        "import copy\n",
        "\n",
        "score_th = 0.3\n",
        "\n",
        "debug_image = copy.deepcopy(test_image)\n",
        "debug_image_width, debug_image_height = debug_image.shape[1], debug_image.shape[0]\n",
        "\n",
        "for i in range(num):\n",
        "    score = scores[i]\n",
        "    bbox = bboxes[i]\n",
        "    class_id = classes[i].astype(np.int)\n",
        "\n",
        "    if score < score_th:\n",
        "        continue\n",
        "\n",
        "    x1, y1 = int(bbox[1] * debug_image_width), int(bbox[0] * debug_image_height)\n",
        "    x2, y2 = int(bbox[3] * debug_image_width), int(bbox[2] * debug_image_height)\n",
        "\n",
        "    cv2.putText(\n",
        "        debug_image, 'ID:' + str(class_id) + ' ' +\n",
        "        class_labels[class_id] + ' ' + '{:.3f}'.format(score),\n",
        "        (x1, y1 - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2,\n",
        "        cv2.LINE_AA)\n",
        "    cv2.rectangle(debug_image, (x1, y1), (x2, y2), (255, 255, 255), 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdwCZTtO_RRX"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.imshow(cv2.cvtColor(debug_image, cv2.COLOR_BGR2RGB) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYHgVohex6ll"
      },
      "source": [
        "# 推論(Inference)\n",
        "形式：Float16量子化(Float16 quantization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWeZRajYxSJu"
      },
      "source": [
        "# モデルロード(Load model)\n",
        "interpreter = tf.lite.Interpreter(model_path='model_fp16.tflite', num_threads=1)\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzzuw65qx5_M"
      },
      "source": [
        "# 入力情報確認(Check input detail)\n",
        "input_details = interpreter.get_input_details()\n",
        "print(input_details)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZBW6onFxSHA"
      },
      "source": [
        "# 出力情報確認(Check output detail)\n",
        "output_details = interpreter.get_output_details()\n",
        "print(output_details)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isBJWUjM1YMj"
      },
      "source": [
        "# クラスラベル確認(Check class label)\n",
        "class_labels = ['???'] * model.model_spec.config.num_classes\n",
        "label_map = model.model_spec.config.label_map\n",
        "for label_id, label_name in label_map.as_dict().items():\n",
        "    class_labels[label_id-1] = label_name\n",
        "\n",
        "print(class_labels) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xadZZv6DxSEU"
      },
      "source": [
        "# 推論用関数(Function for inference)\n",
        "def run_inference_fp16_single_image(\n",
        "        interpreter,\n",
        "        input_image,\n",
        "        input_shape=(320, 320),\n",
        "):\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    x = input_image[:, :, [2, 1, 0]]  # BGR2RGB\n",
        "    x = cv2.resize(x, (input_shape[0], input_shape[1]))\n",
        "    x = x.reshape(1, x.shape[0], x.shape[1], x.shape[2])\n",
        "    x = x.astype(np.float32)\n",
        "    x /= 255.0\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], x)\n",
        "    interpreter.invoke()\n",
        "\n",
        "    boxes = interpreter.get_tensor(output_details[0]['index'])\n",
        "    classes = interpreter.get_tensor(output_details[1]['index'])\n",
        "    scores = interpreter.get_tensor(output_details[2]['index'])\n",
        "    num = interpreter.get_tensor(output_details[3]['index'])\n",
        "\n",
        "    return np.squeeze(boxes), np.squeeze(classes), np.squeeze(scores), int(num[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui5qfMKLW5Pi"
      },
      "source": [
        "# サンプル画像読み込み(Load sample image)\n",
        "test_image = cv2.imread('dataset/000041.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL9d85Tt3zl1"
      },
      "source": [
        "# 推論(Inference)\n",
        "bboxes, classes, scores, num = run_inference_fp16_single_image(\n",
        "    interpreter,\n",
        "    test_image\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mre6Mqztzra_"
      },
      "source": [
        "# 推論結果描画(Inference result drawing)\n",
        "import copy\n",
        "\n",
        "score_th = 0.3\n",
        "\n",
        "debug_image = copy.deepcopy(test_image)\n",
        "debug_image_width, debug_image_height = debug_image.shape[1], debug_image.shape[0]\n",
        "\n",
        "for i in range(num):\n",
        "    score = scores[i]\n",
        "    bbox = bboxes[i]\n",
        "    class_id = classes[i].astype(np.int)\n",
        "\n",
        "    if score < score_th:\n",
        "        continue\n",
        "\n",
        "    x1, y1 = int(bbox[1] * debug_image_width), int(bbox[0] * debug_image_height)\n",
        "    x2, y2 = int(bbox[3] * debug_image_width), int(bbox[2] * debug_image_height)\n",
        "\n",
        "    cv2.putText(\n",
        "        debug_image, 'ID:' + str(class_id) + ' ' +\n",
        "        class_labels[class_id] + ' ' + '{:.3f}'.format(score),\n",
        "        (x1, y1 - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2,\n",
        "        cv2.LINE_AA)\n",
        "    cv2.rectangle(debug_image, (x1, y1), (x2, y2), (255, 255, 255), 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqMtArjs0LdB"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.imshow(cv2.cvtColor(debug_image, cv2.COLOR_BGR2RGB) )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}